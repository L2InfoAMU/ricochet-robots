\hypertarget{classqlearn_1_1Qlearner}{}\section{Référence de la classe qlearn.\+Qlearner}
\label{classqlearn_1_1Qlearner}\index{qlearn.\+Qlearner@{qlearn.\+Qlearner}}
\subsection*{Fonctions membres publiques}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classqlearn_1_1Qlearner_a2358d27a7a8833adaf69138ceda4d7aa}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, game)
\item 
def \hyperlink{classqlearn_1_1Qlearner_aa5d2c9fb82ed55754cab3f485551ba22}{reward} (self, state, action)
\item 
def \hyperlink{classqlearn_1_1Qlearner_a21001f2c11418262b3b0cfc58fb91f72}{learn} (self, nb\+\_\+iter, mu=0.\+9, c=1, explore=1)
\end{DoxyCompactItemize}
\subsection*{Attributs publics}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a69b12b006548c4ea15e63f5e22af8708}\label{classqlearn_1_1Qlearner_a69b12b006548c4ea15e63f5e22af8708}} 
{\bfseries game}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a27bf7d240f5a715866a7dc249dd0bacb}\label{classqlearn_1_1Qlearner_a27bf7d240f5a715866a7dc249dd0bacb}} 
{\bfseries actions}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a2eba21289650ffb2d6fd99ecfac97e63}\label{classqlearn_1_1Qlearner_a2eba21289650ffb2d6fd99ecfac97e63}} 
{\bfseries encoder}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a8bbd7e43cb52617447d6ddb6b67aed79}\label{classqlearn_1_1Qlearner_a8bbd7e43cb52617447d6ddb6b67aed79}} 
{\bfseries state\+\_\+number}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_ad83c3b921b20c82bd5e6aa3ac550b4a5}\label{classqlearn_1_1Qlearner_ad83c3b921b20c82bd5e6aa3ac550b4a5}} 
{\bfseries int\+\_\+to\+\_\+state}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a590de5eb34ceb094ad2ce575064a46c1}\label{classqlearn_1_1Qlearner_a590de5eb34ceb094ad2ce575064a46c1}} 
{\bfseries action\+\_\+number}
\item 
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a85cd72fc90598ce1036f3bfbf1e19cc8}\label{classqlearn_1_1Qlearner_a85cd72fc90598ce1036f3bfbf1e19cc8}} 
{\bfseries qtable}
\end{DoxyCompactItemize}


\subsection{Documentation des constructeurs et destructeur}
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a2358d27a7a8833adaf69138ceda4d7aa}\label{classqlearn_1_1Qlearner_a2358d27a7a8833adaf69138ceda4d7aa}} 
\index{qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def qlearn.\+Qlearner.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{game }\end{DoxyParamCaption})}

\begin{DoxyVerb}construit un apprenant pour le jeu game 
\end{DoxyVerb}
 

\subsection{Documentation des fonctions membres}
\mbox{\Hypertarget{classqlearn_1_1Qlearner_a21001f2c11418262b3b0cfc58fb91f72}\label{classqlearn_1_1Qlearner_a21001f2c11418262b3b0cfc58fb91f72}} 
\index{qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}!learn@{learn}}
\index{learn@{learn}!qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}}
\subsubsection{\texorpdfstring{learn()}{learn()}}
{\footnotesize\ttfamily def qlearn.\+Qlearner.\+learn (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{nb\+\_\+iter,  }\item[{}]{mu = {\ttfamily 0.9},  }\item[{}]{c = {\ttfamily 1},  }\item[{}]{explore = {\ttfamily 1} }\end{DoxyParamCaption})}

\begin{DoxyVerb}apprend la Qtable en simulant nb_iter épisodes de jeu
mu est le facteur de récompense retardée
c le facteur d'apprentissage qui peut varier entre 0 et 1
c = 0 , l'agent n'apprend rien, 
c = 1 , l'agent met à jour complétement la valeur de Q (voir rapport)

explore est le facteur d'exploration qui peut varier entre 0 et 1 :
explore = 0  : l'agent choisit l'action à partir de la meilleure récompense dans la table
explore = 1 : l'agent explore en choisissant toutes ses actions au hasard
\end{DoxyVerb}
 \mbox{\Hypertarget{classqlearn_1_1Qlearner_aa5d2c9fb82ed55754cab3f485551ba22}\label{classqlearn_1_1Qlearner_aa5d2c9fb82ed55754cab3f485551ba22}} 
\index{qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}!reward@{reward}}
\index{reward@{reward}!qlearn\+::\+Qlearner@{qlearn\+::\+Qlearner}}
\subsubsection{\texorpdfstring{reward()}{reward()}}
{\footnotesize\ttfamily def qlearn.\+Qlearner.\+reward (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{state,  }\item[{}]{action }\end{DoxyParamCaption})}

\begin{DoxyVerb}    récompense liée à une action
    Si l'action ne fait pas changer d'état la récompense est -1
    Si l'action fait aboutir à un état final la récompense est 1
    Sinon la récompense est 0
    Après l'appel de cette fonction le jeu est dans le nouvel etat 
\end{DoxyVerb}
 

La documentation de cette classe a été générée à partir du fichier suivant \+:\begin{DoxyCompactItemize}
\item 
qlearn.\+py\end{DoxyCompactItemize}
